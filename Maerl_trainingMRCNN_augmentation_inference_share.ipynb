{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC-KeG3bQa4E"
   },
   "source": [
    "# Training a  Mask R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook used to apply a mask R-cnn model in inference mode to classify live maerl in imagery of the sea-bed obtained from drop-down cameras. \n",
    "Originally based on https://github.com/matterport/Mask_RCNN Also see this repo for more examples (in samples folder) and explanation of config parameters.\n",
    "Platform used in this instance : JupyterLab on MAGEOHub (massive online GPU for Earth Observation at Plymouth Marine Lab).\n",
    "This notebook loads necessary modules , loads images to be classified (imagery in tiff or jpeg )  loads pre-trained weights and outputs classified rasters. This is a binary classification of live maerl/ not live maerl. \n",
    "Many thanks to Dan Simms (University of Cranfield) for code examples and Stephen Goult & Dan Clewley  (Plymouth Marine Laboratory/ NEODAAS) for troubleshooting suggestions and use of MAGEO.\n",
    "Keen to hear about other applications - karen.frake@nature.scot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) \\n[GCC 9.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCeDYYS81MTd"
   },
   "source": [
    "!ln -s /lustre_scratch/karennaturescot ~/lustre_scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNruEidSroFv"
   },
   "source": [
    "##Data transfer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#%%bash\n",
    "os.chdir('/lustre_scratch/karennaturescot')\n",
    "#os.chdir('/lustre_scratch/karennaturescot/Deep_learning_maerl')\n",
    "#cd mask_rcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre_scratch/karennaturescot'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep_learning_maerl\n",
      "delete\n",
      "delete1\n",
      "karennaturescot\n",
      "mask_rcnn\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#os.chdir('/lustre_scratch/karennaturescot')\n",
    "#cd mask_rcnn\n",
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/lustre_scratch/karennaturescot/mask_rcnn')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre_scratch/karennaturescot'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Collecting pip==21.0.1\n",
      "  Using cached pip-21.0.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.1\n",
      "    Uninstalling pip-21.1:\n",
      "      Successfully uninstalled pip-21.1\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Successfully installed pip-21.0.1\n",
      "Collecting keras==2.4.3\n",
      "  Using cached Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.8/site-packages (from keras==2.4.3) (1.6.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.8/site-packages (from keras==2.4.3) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from keras==2.4.3) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.8/site-packages (from keras==2.4.3) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from h5py->keras==2.4.3) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting cython\n",
      "  Using cached Cython-0.29.24-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "Installing collected packages: cython\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 0.19.1 requires cupy-cuda112, which is not installed.\u001b[0m\n",
      "Successfully installed cython-0.29.24\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.5.3.56-cp38-cp38-manylinux2014_x86_64.whl (49.9 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.3.56\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pip==21.0.1\n",
    "!pip install keras==2.4.3 # tried 2.1.5 #07 06 20212.4.3\n",
    "!pip install cython\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image==0.16.2\n",
      "  Using cached scikit_image-0.16.2-cp38-cp38-manylinux1_x86_64.whl (26.5 MB)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image==0.16.2) (3.4.1)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image==0.16.2) (8.1.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image==0.16.2) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image==0.16.2) (1.6.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image==0.16.2) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image==0.16.2) (2.5.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from imageio>=2.3.0->scikit-image==0.16.2) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (0.10.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.16.2) (1.15.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.8/site-packages (from networkx>=2.0->scikit-image==0.16.2) (4.4.2)\n",
      "Installing collected packages: scikit-image\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.18.1\n",
      "    Uninstalling scikit-image-0.18.1:\n",
      "      Successfully uninstalled scikit-image-0.18.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "imgaug 0.4.0 requires opencv-python-headless, which is not installed.\u001b[0m\n",
      "Successfully installed scikit-image-0.16.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image==0.16.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jN7xgNLpGlic"
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15516,
     "status": "ok",
     "timestamp": 1620028058898,
     "user": {
      "displayName": "Eroded Peat",
      "photoUrl": "",
      "userId": "11363673335537033928"
     },
     "user_tz": -60
    },
    "id": "GGve0Heu1vyH",
    "outputId": "248f3255-1494-46e6-a4d7-ed468b3bd217"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests) (4.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.8 -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt-get install libgdal-dev -y\n",
    "apt-get install python-gdal -y\n",
    "apt-get install python-numpy python-scipy -y\n",
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.10.1\n",
      "  latest version: 4.10.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - gdal\n",
      "\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2020.12.5-ha878542_0 --> 2021.5.30-ha878542_0\n",
      "  certifi                          2020.12.5-py38h578d9bd_1 --> 2021.5.30-py38h578d9bd_0\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxK39YZQXbIV"
   },
   "source": [
    "## Model code\n",
    "\n",
    "The following steps are taken from the example notebooks on original repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/lustre_scratch/karennaturescot'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##if needed\n",
    "os.chdir('/lustre_scratch/karennaturescot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZyQqyp2j0jL4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lustre_scratch/karennaturescot\n",
      "/lustre_scratch/karennaturescot/mask_rcnn\n",
      "/lustre_scratch/karennaturescot/mask_rcnn/samples/maerl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "#import gdal\n",
    "print(os.getcwd())\n",
    "\n",
    "ROOT_DIR = os.path.abspath('/lustre_scratch/karennaturescot/mask_rcnn')\n",
    "#lustre_scratch/karennaturescot/mask_rcnn\n",
    "MAERL_DIR = os.path.abspath('/lustre_scratch/karennaturescot/mask_rcnn/samples/maerl')\n",
    "DATA_DIR = os.path.abspath('/lustre_scratch/karennaturescot/Deep_learning_maerl')\n",
    "\n",
    "#sys.path.append(ROOT_DIR)\n",
    "os.chdir(ROOT_DIR)\n",
    "#os.chdir(DATA_DIR)\n",
    "print(os.getcwd())\n",
    "from mrcnn import visualize\n",
    "from mrcnn import utils\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sys.path.append(MAERL_DIR)\n",
    "\n",
    "os.chdir(MAERL_DIR)\n",
    "#import maerl_mageo_nucleiConfig\n",
    "#import maerl_mageo_v2\n",
    "import maerl_tiny\n",
    "#import maerl_mageo\n",
    "#import maerl_mageo_jpg\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1619781056895,
     "user": {
      "displayName": "Eroded Peat",
      "photoUrl": "",
      "userId": "11363673335537033928"
     },
     "user_tz": -60
    },
    "id": "SzckP6Q4fCMq",
    "outputId": "dc3797db-ee43-494a-e30a-4bb6c9246fb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        10600\n",
      "DETECTION_MIN_CONFIDENCE       0.0001\n",
      "DETECTION_NMS_THRESHOLD        0.9\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  3712\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  2752\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              pad64\n",
      "IMAGE_SHAPE                    [3712 3712    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           maerlinfer\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        7000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  9000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "SAVE_FREQ                      epoch\n",
      "STEPS_PER_EPOCH                5000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  False\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#new class in script not .py\n",
    "\n",
    "#OUTPUT_DIR = os.path.abspath('/content/drive/MyDrive/Deep_learning_maerl/output')\n",
    "OUTPUT_DIR = os.path.abspath('/lustre_scratch/karennaturescot/Deep_learning_maerl/output')\n",
    "MODEL_DIR = os.path.join(OUTPUT_DIR, 'logs')\n",
    "\n",
    "class inferconfig(maerl_tiny.MaerlShapesConfig):\n",
    "  NAME = 'maerlinfer'\n",
    "\n",
    "  #IMAGES_PER_GPU = 2\n",
    "  IMAGES_PER_GPU = 1\n",
    "\n",
    "  GPU_COUNT = 1\n",
    "\n",
    "  NUM_CLASSES = 1 + 1  # Just maerl\n",
    "\n",
    "  IMAGE_RESIZE_MODE = \"pad64\" #\"pad64\"#\"square\"# \"pad64\" #\"none\" #\"crop\" #\"square\"\n",
    " #note  that none didn't work\n",
    "  #FPN_CLASSIF_FC_LAYERS_SIZE =256# 1024 # would also need changing if max dim is changed?\n",
    "   \n",
    "  USE_MINI_MASK = False\n",
    "  \n",
    "  #DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "    # Non-maximum suppression threshold for detection\n",
    "  #DETECTION_NMS_THRESHOLD =0.7 # 0.7 as for nucleus example 0.9 #\n",
    "      # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "  RPN_NMS_THRESHOLD = 0.9#0.3 v13# 0.9 v11#0.99v7 #0.9v5#0.3 v4# 0.7 #as for nucleus example 0.9\n",
    "  PRE_NMS_LIMIT = 9000 #6000 V4\n",
    "  #POST_NMS_ROIS_TRAINING = 1000\n",
    "  POST_NMS_ROIS_INFERENCE =7000# 8000v7# 7000v6# 6000 v4 # 10002000# 1000\n",
    "  DETECTION_MIN_CONFIDENCE = 0.0001# 0.00001 v13#0.0001 v10, v9 #0.001 v8 # 0.01 v7 #0.01 v6 #0.2 v5\n",
    "  DETECTION_NMS_THRESHOLD =0.9 #0.5 v12#v11 0.9#0.99 v7#0.9v6# 0.1v5# 0.2 the overlap of non maximal bounding boxes above which they are discarded\n",
    "\n",
    "      # Max number of final detections per image\n",
    "  DETECTION_MAX_INSTANCES = 10600#10500 v9 #10000v6 #10000 v4# 500 #1000 # tried 20000 crashed, 12000crashed, 11000crashed, 10900crashed\n",
    "  IMAGE_MAX_DIM =3712# 3648 #needs to be multple of 64?\n",
    "        # square: Resize and pad with zeros to get a square image\n",
    "    #         of size [max_dim, max_dim].\n",
    "  IMAGE_MIN_DIM =  2752# \n",
    "inference_config = inferconfig()\n",
    "inference_config.display()\n",
    "\n",
    "##note - v12, v13 worse than 11,10,9 - use exisiting config to maximise number of classifications without crashing mageohub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18277,
     "status": "ok",
     "timestamp": 1619781165630,
     "user": {
      "displayName": "Eroded Peat",
      "photoUrl": "",
      "userId": "11363673335537033928"
     },
     "user_tz": -60
    },
    "id": "y1qhYXS5SWis",
    "outputId": "b8c20f64-3c71-489e-f1a6-50810eb2e29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Loading weights from  /lustre_scratch/karennaturescot/Deep_learning_maerl/output/logs/maerl20210729T1317/mask_rcnn_maerl_0150.h5\n",
      "Re-starting from epoch 150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model_path =\"/content/drive/MyDrive/Deep_learning_maerl/output/logs/maerl20210406T1113/mask_rcnn_maerl_runII.h5\"\n",
    "\n",
    "model_path =\"/lustre_scratch/karennaturescot/Deep_learning_maerl/output/logs/maerl20210729T1317/mask_rcnn_maerl_0150.h5\"\n",
    "\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "\n",
    "#model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKSzsiE-E5eE"
   },
   "source": [
    "#load in image to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zxaG1ugL1KxW"
   },
   "outputs": [],
   "source": [
    "##class functionality to load in jpg and tiff\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from osgeo import ogr\n",
    "import sys\n",
    "import logging\n",
    "import random\n",
    "\n",
    "def scale_to_8bit(pix):\n",
    "  scaled = np.zeros(pix.shape, dtype=float)\n",
    "  for b in range(len(pix)):\n",
    "      scaled[b] = pix[b]/pix[b].max()\n",
    "  \n",
    "  return (scaled*255).astype('uint8')\n",
    "\n",
    "class MaerlShapesTEST(utils.Dataset):\n",
    "  def load_maerl(self, dataset_dir, skip_empty=False):\n",
    "           \n",
    "    if not os.path.exists(dataset_dir):\n",
    "      logging.error('Path {} does not exist'.format(dataset_dir))\n",
    "      return  \n",
    "    \n",
    "    image_dir = 'images'\n",
    "    json_dir = 'geometries'\n",
    "    print(image_dir)\n",
    "    print(json_dir)\n",
    "    print(dataset_dir)\n",
    "    print(os.path.join(dataset_dir,image_dir))\n",
    "    #image_files = glob.glob(os.path.join(dataset_dir, image_dir, '*.tif'))\n",
    "    image_files = glob.glob(os.path.join(dataset_dir, image_dir, '*.tif'))+glob.glob(os.path.join(dataset_dir, image_dir, '*.JPG'))\n",
    "    #image_files1 = glob.glob(os.path.join(dataset_dir, image_dir, '*.tif'))\n",
    "    #print(image_files1)\n",
    "    #image_files1 = glob.glob(os.path.join(dataset_dir, image_dir, '*.jpg'))\n",
    "    #print(image_files1)\n",
    "    print(image_files)\n",
    "    \n",
    "    image_ids = [int(re.findall(r'\\d+', img)[0]) for img in image_files]\n",
    "    print(image_ids)\n",
    "    # image_ids = [int(re.findall(r'\\d+', img)[2]) for img in image_files]\n",
    "    # json = glob.glob(os.path.join(dataset_dir, json_dir, '*.geojson'))\n",
    "    #json = glob.glob(os.path.join(dataset_dir, json_dir, '*.json'))\n",
    "    #print(json[0])\n",
    "    # json_ids = [int(re.findall(r'\\d+', js)[2]) for js in json]\n",
    "    #json_ids = [int(re.findall(r'\\d+', js)[0]) for js in json]\n",
    "    #print(json_ids[0])\n",
    "    \n",
    "    if os.path.exists(os.path.join(dataset_dir, json_dir)):      \n",
    "      json = glob.glob(os.path.join(dataset_dir, json_dir, '*.json'))\n",
    "      json_ids = [int(re.findall(r'\\d+', js)[0]) for js in json]\n",
    "      \n",
    "      for i, id_ in enumerate(image_ids):\n",
    "        src = gdal.Open(image_files[i])\n",
    "        if has_zero_instances(json[json_ids.index(id_)]):\n",
    "          if skip_empty:\n",
    "            continue # zero instance image\n",
    "\n",
    "        self.add_image(\n",
    "          \"maerl\",\n",
    "          image_id=id_,\n",
    "          path=image_files[i],\n",
    "          width=3712 ,# adjusted for padding without distortion,\n",
    "          height=2752, #adjusted for padding without distortion,\n",
    "          polygons=json[json_ids.index(id_)],\n",
    "          geotransform=src.GetGeoTransform()\n",
    "        )\n",
    "    else:\n",
    "      for i, id_ in enumerate(image_ids):\n",
    "        src = gdal.Open(image_files[i])\n",
    "        self.add_image(\n",
    "          \"maerl\",\n",
    "          image_id=id_,\n",
    "          path=image_files[i],\n",
    "          #width=src.RasterXSize,\n",
    "          #height=src.RasterYSize,\n",
    "          width=3712, # adjusted for padding without distortion,\n",
    "          height=2752, #adjusted for padding without distortion,\n",
    "          geotransform=src.GetGeoTransform()\n",
    "        )\n",
    "    self.add_class('maerl', 1, 'maerl')\n",
    "\n",
    "    #self.add_class('spacenet', 1, 'Building')\n",
    "   #for i, id_ in enumerate(image_ids):\n",
    "    #  src = gdal.Open(image_files[i])\n",
    "    #  self.image_info[i] = {\n",
    "       #   'path': image_files[i],\n",
    "        #  'polygons': json[json_ids.index(id_)],\n",
    "        #  'height': src.RasterYSize,\n",
    "         # 'width': src.RasterXSize,\n",
    "        #  'geotransform': src.GetGeoTransform(),\n",
    "        #  'source': \"maerlsource\",\n",
    "     #    'id': i,\n",
    " #    } #id needed for prepare data method\n",
    "\n",
    "    #image_ids.sort()\n",
    "    \n",
    "    #self.num_Images = len(self.image_info)\n",
    "    #self.nrange = np.arange(self.num_Images)\n",
    "    \n",
    "    \n",
    "    #new_image_info = []\n",
    "    #for i in self.nrange:\n",
    "      #new_image_info.append(self.image_info.get(i))\n",
    "\n",
    "    #self.image_info = new_image_info\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #self._image_ids = image_ids\n",
    "    \n",
    "  def load_image(self, image_id):\n",
    "    img = gdal.Open(self.image_info[image_id]['path'])\n",
    "    byte_img = scale_to_8bit(img.ReadAsArray())\n",
    "    padrows = np.ones((3,16, 3648),dtype=np.uint8)\n",
    "    padcolumns=np.ones((3,2752,64),dtype=np.uint8)\n",
    "    byte_img = np.append(byte_img,padrows,axis=1)\n",
    "    byte_img = np.append(byte_img, padcolumns,axis =2)\n",
    "    \n",
    "    return byte_img.transpose(1, 2, 0)\n",
    "  \n",
    "  #from balloon\n",
    "  def image_reference(self, image_id):\n",
    "      \"\"\"Return the id of the image.\"\"\"\n",
    "      info = self.image_info[image_id]\n",
    "      if info[\"source\"] == \"maerl\":\n",
    "          return info[\"id\"]\n",
    "      else:\n",
    "          super(MaerlShapes, self).image_reference(image_id)\n",
    "          \n",
    " \n",
    "  def load_mask(self, image_id):\n",
    "    '''Load instance masks for the given image.\n",
    "      \n",
    "      Returns:\n",
    "        masks: A bool ndarray of binary masks with\n",
    "          shape [h, w, instance count]\n",
    "        class_ids: a 1d ndarray of class IDs of the\n",
    "          instance masks.\n",
    "    '''\n",
    "    image_info = self.image_info[image_id]\n",
    "    instances = []\n",
    "    if 'polygons' in image_info:\n",
    "      feats = load_as_features(image_info['polygons'])\n",
    "      lyr = feats.GetLayer()\n",
    "\n",
    "      # Rasterize each feature as a new instance\n",
    "      driver = gdal.GetDriverByName('MEM')\n",
    "      for feat in lyr:\n",
    "        # Each feature is a new layer\n",
    "        outdriver = ogr.GetDriverByName('MEMORY')\n",
    "        out = outdriver.CreateDataSource('memData')\n",
    "\n",
    "        #tmp = outdriver.Open('memData', 1)\n",
    "        out_layer = out.CreateLayer('layer', geom_type=ogr.wkbPolygon)\n",
    "        out_layer.CreateFeature(feat)\n",
    "\n",
    "        mem_raster = driver.Create(\n",
    "            '',\n",
    "            image_info['width'],\n",
    "            image_info['height'],\n",
    "            gdal.GDT_Byte\n",
    "        )\n",
    "        mem_raster.SetGeoTransform(image_info['geotransform'])\n",
    "        gdal.RasterizeLayer(mem_raster, [1], out_layer, burn_values=[1])\n",
    "\n",
    "        instances.append(mem_raster.GetRasterBand(1).ReadAsArray())\n",
    "    \n",
    "    if len(instances) !=0:\n",
    "      mask = np.stack(instances, axis=2).astype(np.bool)\n",
    "\n",
    "      # All the same class\n",
    "      classes = np.ones(mask.shape[-1], dtype=np.int32)\n",
    "      \n",
    "      return mask, classes\n",
    "\n",
    "    else:\n",
    "      # Call super class to return an empty mask\n",
    "      return super(MaerlShapesTEST, self).load_mask(image_id)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1696,
     "status": "ok",
     "timestamp": 1619781218524,
     "user": {
      "displayName": "Eroded Peat",
      "photoUrl": "",
      "userId": "11363673335537033928"
     },
     "user_tz": -60
    },
    "id": "X19DS5b41T1-",
    "outputId": "e5189fd0-dffb-4973-d4c3-a1dcae5b7c24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\n",
      "geometries\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/infer\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images\n",
      "['/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6951.JPG', '/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6952.JPG', '/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6953.JPG']\n",
      "[6951, 6952, 6953]\n",
      "loaded data\n",
      "[{'id': 6951, 'source': 'maerl', 'path': '/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6951.JPG', 'width': 3712, 'height': 2752, 'geotransform': (0.0, 1.0, 0.0, 0.0, 0.0, 1.0)}, {'id': 6952, 'source': 'maerl', 'path': '/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6952.JPG', 'width': 3712, 'height': 2752, 'geotransform': (0.0, 1.0, 0.0, 0.0, 0.0, 1.0)}, {'id': 6953, 'source': 'maerl', 'path': '/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6953.JPG', 'width': 3712, 'height': 2752, 'geotransform': (0.0, 1.0, 0.0, 0.0, 0.0, 1.0)}]\n",
      "Infer image Count: 3\n",
      "[0 1 2]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "inferdataset1 = MaerlShapesTEST()\n",
    "INFER_DIR= os.path.abspath('/lustre_scratch/karennaturescot/Deep_learning_maerl/infer')\n",
    "\n",
    "#\"/lustre_scratch/karennaturescot/Deep_learning_maerl/output/logs/maerl20210611T1108/mask_rcnn_maerl_0050.h5\"\n",
    "inferdataset1.load_maerl(INFER_DIR, skip_empty=True)\n",
    "inferdataset1.prepare() #previously called within split, therefore need to call separately\n",
    "print(\"loaded data\")\n",
    "print(inferdataset1.image_info)\n",
    "# Split\n",
    "#dataset_train, dataset_test = dataset.split_train_test(proportion_train=0.7)\n",
    "print(\"Infer image Count: {}\".format(len(inferdataset1.image_ids)))\n",
    "print(inferdataset1.image_ids)\n",
    "#print(\"Class Count: {}\".format(dataset_train.num_classes))\n",
    "#for i, info in enumerate(dataset_train.class_info):\n",
    "#    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    "#print(\"Test image Count: {}\".format(len(inferdataset.image_ids)))\n",
    "#print(\"Class Count: {}\".format(dataset_test.num_classes))\n",
    "#for i, info in enumerate(dataset_test.class_info):\n",
    "#    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    "print(inferdataset1.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5702,
     "status": "ok",
     "timestamp": 1619513199862,
     "user": {
      "displayName": "Eroded Peat",
      "photoUrl": "",
      "userId": "11363673335537033928"
     },
     "user_tz": -60
    },
    "id": "PIj7cLntFheF",
    "outputId": "6568bced-2980-4cb1-b661-e27ba1dbdc4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6951.JPG\n",
      "Output file name:\n",
      "infer_IMG_6951.JPG\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/output/images/infer_IMG_6951.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image ID:maerl.6951(0)6951\n",
      "Processing 1 images\n",
      "image                    shape: (2752, 3712, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 2752, 3712, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 3712.00000  int64\n",
      "anchors                  shape: (1, 2551362, 4)       min:   -0.13160  max:    1.10834  float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2752, 3712)\n",
      "1\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6952.JPG\n",
      "Output file name:\n",
      "infer_IMG_6952.JPG\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/output/images/infer_IMG_6952.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image ID:maerl.6952(1)6952\n",
      "Processing 1 images\n",
      "image                    shape: (2752, 3712, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 2752, 3712, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 3712.00000  int64\n",
      "anchors                  shape: (1, 2551362, 4)       min:   -0.13160  max:    1.10834  float32\n",
      "(2752, 3712)\n",
      "2\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/infer/images/IMG_6953.JPG\n",
      "Output file name:\n",
      "infer_IMG_6953.JPG\n",
      "/lustre_scratch/karennaturescot/Deep_learning_maerl/output/images/infer_IMG_6953.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are using the default load_mask(), maybe you need to define your own one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image ID:maerl.6953(2)6953\n",
      "Processing 1 images\n",
      "image                    shape: (2752, 3712, 3)       min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 2752, 3712, 3)    min: -123.70000  max:  151.10000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 3712.00000  int64\n",
      "anchors                  shape: (1, 2551362, 4)       min:   -0.13160  max:    1.10834  float32\n",
      "(2752, 3712)\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "\n",
    "for image_id,idx in enumerate(inferdataset1.image_ids, start =0):\n",
    "    print(image_id)\n",
    "    inputfp= [a_dict[\"path\"] for a_dict in inferdataset1.image_info][image_id]\n",
    "    print(inputfp)\n",
    "    lengthinputfp = len(inputfp)\n",
    "    leninputname = lengthinputfp - 65\n",
    "    outputname = 'infer_' + inputfp[(leninputname*-1):]\n",
    "    ##v8 crashed, only output for a single image rather than 2 that were input and reached limit on memory while running\n",
    "    print(\"Output file name:\")\n",
    "    print(outputname)\n",
    "    OUTPUT_DIR = os.path.abspath('/lustre_scratch/karennaturescot/Deep_learning_maerl/output/images')\n",
    "    outputfp=os.path.join(OUTPUT_DIR,outputname)\n",
    "    print(outputfp)\n",
    "    \n",
    "    image,image_meta, gt_class_id, gt_bbox, gt_mask = \\\n",
    "        modellib.load_image_gt(inferdataset1, inference_config, image_id)\n",
    "    info = inferdataset1.image_info[image_id]\n",
    "    print(\"image ID:{}.{}({}){}\".format(info[\"source\"],info[\"id\"],image_id, inferdataset1.image_reference(image_id)))\n",
    "#run object detection\n",
    "    results = model.detect([image],verbose =1)\n",
    "    r = results[0]\n",
    "    outarray =np.sum(r['masks'],axis=2)\n",
    "    outarray = np.where(outarray==0,outarray, 1)\n",
    "    outarray = outarray.astype(np.uint8)\n",
    "    #edit so edge pixels removed \n",
    "    image = Image.fromarray(outarray)\n",
    "    image = ImageOps.crop(image, (0,0,64,16)) \n",
    "    #create blank output array of zeros\n",
    "    print(outarray.shape)\n",
    "    image.save(outputfp)\n",
    "\n",
    "#outarray = np.zeros([r['masks'].shape[0],r['masks'].shape[1],1])\n",
    "#print(outarray.shape)\n",
    "#print(outarray[:3,:3,:])\n",
    "#print(np.sum(r['masks'][:,:,:100]))\n",
    "#print(outarray)\n",
    "#outarray=np.sum(r['masks'], axis=2)\n",
    "#print(outarray.shape)\n",
    "#print(outarray)\n",
    "#print(outarray.max())\n",
    "#outarray = np.where(outarray ==0, outarray, 1)\n",
    "#outarray= outarray.astype(np.uint8)\n",
    "#print(outarray.max())\n",
    "\n",
    "#for i in enumerate (r['masks'].shape[2]:\n",
    "\n",
    "#use PIL for imagery that is not georeferenced\n",
    "\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Maerl_trainingMRCNN.ipynb",
   "provenance": [
    {
     "file_id": "12rGpgp11S8Xnm1FfeklFAc-wrUo2prFn",
     "timestamp": 1614095323874
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
